{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup + Introduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from tensorflow.keras import layers as lyrs, optimizers as opts, activations as acts, losses as ls\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training, evaluation, and inference**\n",
    "\n",
    ">> **The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build `graphs of layers`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Creating a Linear totplogy using functional layer!!\n",
    "    Topology:\n",
    "        Inputs([784]) => Dense(units= 64, 'relu') => Dense(units= 32, 'relu') => Dense(units= 10, 'softmax')\n",
    "'''\n",
    "\n",
    "inp = tfk.Input(shape=[784], name='Input_Layer')\n",
    "d1 = lyrs.Dense(128, 'relu', name= 'Dense_1')(inp)\n",
    "d2 = lyrs.Dense(64, 'relu', name= 'Dense_2')(d1)\n",
    "out = lyrs.Dense(10, 'softmax', name= 'OutputLayer')(d2)\n",
    "\n",
    "\n",
    "model = tfk.Model(inputs= inp, outputs= out, name='Classification_Model')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk.utils.plot_model(model, to_file='model.png', show_shapes= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "'''\n",
    "    1. Preparing data\n",
    "    2. Building the Model\n",
    "    3. Train and evaluate \n",
    "'''\n",
    "\n",
    "dataset = tfk.datasets.mnist\n",
    "(tr_data, tr_lbls), (ts_data, ts_lbls) = dataset.load_data()\n",
    "\n",
    "# We Flatten the incoming tensor, to convert its dimensions from [28, 28] to (28 x 28)\n",
    "# We use astype to change type of data\n",
    "\n",
    "print(tr_data.shape)\n",
    "print(tr_data.dtype)\n",
    "\n",
    "tr_data = lyrs.Flatten()(tr_data).astype('float32') / 255.0\n",
    "ts_data = ts_data.reshape(-1,784).astype('float32') / 255.0\n",
    "\n",
    "print(ts_data.shape)\n",
    "print(tr_data.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer= opts.Adam(learning_rate= 0.005),\n",
    "    loss= ls.SparseCategoricalCrossentropy(),\n",
    "    metrics= ['accuracy']\n",
    ")\n",
    "\n",
    "his = model.fit(\n",
    "    tr_data,\n",
    "    tr_lbls,\n",
    "    validation_split=0.25,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_history(history, metric):\n",
    "    r = len(history[metric])\n",
    "    plt.plot(history[metric], label='Training')\n",
    "    plt.plot(history['val_'+ metric], label='Validation')\n",
    "    plt.title(metric)\n",
    "    \n",
    "    if metric == 'loss':\n",
    "        plt.ylim([0, 1])\n",
    "    else:\n",
    "        plt.ylim([0.9, 1.0])\n",
    "    plt.legend()\n",
    "        \n",
    "\n",
    "history = his.history\n",
    "print(history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_history(history, 'loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_history(history, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save and serialize**\n",
    "**The standard way to save a functional model is to call model.save() to save the entire model as a single file. You can later recreate the same model from this file, even if the code that built the model is no longer available.**\n",
    "\n",
    "> **`The Saved Model includes:`**\n",
    "1. **Model Architecture**\n",
    "2. **Model Weights**\n",
    "3. **Model training config**\n",
    "4. **Optimizer and its state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Model\n",
    "model.save('SavedModel')\n",
    "\n",
    "# delete existing model\n",
    "# !! del model !!\n",
    "\n",
    "# Reloading Model\n",
    "model_loaded = tfk.models.load_model('SavedModel')\n",
    "pred = model_loaded(ts_data[:10])\n",
    "\n",
    "\n",
    "tf.nn.softmax(pred)\n",
    "for i in pred:\n",
    "    print(np.argmax(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reusing graph of layers to define multiple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will create an Encoder by stacking layers.\n",
    "# Then, we will reuse the existing layers graph to instantiate new model that decodes the encoder-output.\n",
    "\n",
    "encoder_inp = lyrs.Input((28, 28, 1), name='InputLayer')\n",
    "x = lyrs.Conv2D(128, 3, activation='relu')(encoder_inp)\n",
    "x = lyrs.Conv2D(128, 3, activation='relu')(x)\n",
    "x = lyrs.MaxPooling2D(3)(x)\n",
    "x = lyrs.Conv2D(64, 3, activation='relu')(x)\n",
    "x = lyrs.Conv2D(64, 3, activation='relu')(x)\n",
    "encoder_out = lyrs.GlobalMaxPooling2D()(x)\n",
    "\n",
    "model_encoder = tfk.Model(encoder_inp, encoder_out, name='Encoder')\n",
    "model_encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating the decoder!!\n",
    "autoencoder_inp = lyrs.Reshape((8, 8, 1))(encoder_out)\n",
    "x = lyrs.Conv2DTranspose(128, 3, activation='relu')(autoencoder_inp)\n",
    "x = lyrs.Conv2DTranspose(64, 3, activation='relu')(x)\n",
    "x = lyrs.UpSampling2D(3)(x)\n",
    "x = lyrs.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "autoencoder_out = lyrs.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "model_autoencoder = tfk.Model(encoder_inp, autoencoder_out, name='autoencoder')\n",
    "model_autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Callable Models, just like layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Treating `NeuralNet-Models` like `KerasLayers` allows us to design modular-Models, which can take in any specific input and produce an output. Models can also be combined||stacked like layers to form pipelines(Model architecture)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    In this part, we are going to form a autoencoder by \n",
    "    first creating seperate encoders and decoders, then chaining them together \n",
    "    to form autoencoder architecture\n",
    "\"\"\"\n",
    "\n",
    "Encoder_Inp = tfk.Input(shape=(150, 150, 1), name='Encoded_Image')\n",
    "lyr = lyrs.Conv2D(128, 3, activation='relu')(Encoder_Inp)\n",
    "lyr = lyrs.Conv2D(128, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2D(128, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.MaxPooling2D(3)(lyr)\n",
    "\n",
    "lyr = lyrs.Conv2D(64, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2D(64, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2D(32, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.MaxPooling2D(3)(lyr)\n",
    "\n",
    "lyr = lyrs.Conv2D(32, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2D(32, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2D(16, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.MaxPooling2D(2)(lyr)\n",
    "Encoder_Out = lyrs.GlobalMaxPooling2D()(lyr)\n",
    "\n",
    "ModelEncoder = tfk.Model(Encoder_Inp, Encoder_Out, name='Encoder')\n",
    "ModelEncoder.summary()\n",
    "\n",
    "\n",
    "Decoder_Inp = tfk.Input(shape=(16, ), name='Encoded_Image')\n",
    "lyr = lyrs.Reshape((4, 4, 1))(Decoder_Inp)\n",
    "lyr = lyrs.UpSampling2D(3)(lyr)\n",
    "\n",
    "lyr = lyrs.Conv2DTranspose(32, 2, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2DTranspose(32, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2DTranspose(64, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2DTranspose(64, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.UpSampling2D(2)(lyr)\n",
    "\n",
    "lyr = lyrs.Conv2DTranspose(128, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2DTranspose(128, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.UpSampling2D(3)(lyr)\n",
    "\n",
    "lyr = lyrs.Conv2DTranspose(64, 3, activation='relu')(lyr)\n",
    "lyr = lyrs.Conv2DTranspose(64, 3, activation='relu')(lyr)\n",
    "output = lyrs.Conv2DTranspose(1, 3, activation='relu')(lyr)\n",
    "\n",
    "ModelDecoder = tfk.Model(Decoder_Inp, output, name='Decoder')\n",
    "ModelDecoder.summary()\n",
    "\n",
    "autoenc_inp = tfk.Input((150, 150, 1), name='AutoEncoder_Input')\n",
    "\n",
    "encoded_image = ModelEncoder(autoenc_inp)\n",
    "decoded_image = ModelDecoder(encoded_image)\n",
    "\n",
    "autoencoder = tfk.Model(autoenc_inp, decoded_image, name='AutoEncoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = tfk.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "x = lyrs.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = lyrs.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = lyrs.MaxPooling2D(3)(x)\n",
    "x = lyrs.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = lyrs.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = lyrs.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = tfk.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = tfk.Input(shape=(16,), name=\"encoded_img\")\n",
    "x = lyrs.Reshape((4, 4, 1))(decoder_input)\n",
    "x = lyrs.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = lyrs.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = lyrs.UpSampling2D(3)(x)\n",
    "x = lyrs.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = lyrs.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "\n",
    "decoder = tfk.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = tfk.Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = tfk.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ensemble**\n",
    "\n",
    "> **As you can see, the model can be nested: a model can contain sub-models (since a model is just like a layer). A common use case for model nesting is `ensembling`. For example, here's how to ensemble a set of models into a single model that `averages their predictions`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Model(name):\n",
    "    inp = tfk.Input(shape=(256, ))\n",
    "    lyr = lyrs.Dense(128, activation=acts.relu)(inp)\n",
    "    lyr = lyrs.Dense(64, activation=acts.relu)(lyr)\n",
    "    out = lyrs.Dense(16, activation=acts.relu)(lyr)\n",
    "    return tfk.Model(inp, out, name=name)\n",
    "\n",
    "# Creating 3 Samilar Models...\n",
    "m1 = get_Model('Model_1')\n",
    "m2 = get_Model('Model_2')\n",
    "m3 = get_Model('Model_3')\n",
    "\n",
    "# Calling the models on an input-layer...\n",
    "inp = tfk.Input(shape=(256, ))\n",
    "y1, y2, y3 = m1(inp), m2(inp), m3(inp)\n",
    "\n",
    "# Averaging the models_outputs using average layer...\n",
    "out = lyrs.average([y1, y2, y3])\n",
    "\n",
    "# Ensemble learning\n",
    "EnsmebleModel = tfk.Model(inputs= inp, outputs= out, name='Ensemble_Model')\n",
    "EnsmebleModel.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Manipulate complex graph topologies**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### **Multi Inputs / Outputs**\n",
    "\n",
    "**Printing Movie Tickets for customers**\n",
    "\n",
    "**`Inputs:`**\n",
    "1. The Title of the ticket\n",
    "2. The text body of the ticket(categorical input)\n",
    "3. Tags added by the user\n",
    "\n",
    "**`Outputs:`**\n",
    "1. Priority between 0-1\n",
    "2. The department that should handle the ticket(softmax over the set of departments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12 # Number of unique issue-tags.\n",
    "num_words = 10000 # Size of vocabulary when preprocessing the text.\n",
    "num_depts = 4 # Number of departments for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = tfk.Input(\n",
    "    shape=(None,), name=\"title\"\n",
    ")  # Variable-length sequence of ints\n",
    "\n",
    "body_input = tfk.Input(\n",
    "    shape=(None,), name=\"body\"\n",
    ")  # Variable-length sequence of ints\n",
    "\n",
    "\n",
    "tags_input = tfk.Input(\n",
    "    shape=(num_tags,), name=\"tags\"\n",
    ")  # Binary vectors of size `num_tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = lyrs.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = lyrs.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = lyrs.Bidirectional(lyrs.LSTM(128))(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = lyrs.Bidirectional(lyrs.LSTM(128))(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = lyrs.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = lyrs.Dense(1, name=\"priority\")(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = lyrs.Dense(num_departments, name=\"department\")(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = tfk.Model(\n",
    "    inputs=[title_input, body_input, tags_input],\n",
    "    outputs=[priority_pred, department_pred],\n",
    ")\n",
    "\n",
    "tfk.utils.plot_model(model, 'Model_TicketClassifier.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tfk.optimizers.RMSprop(1e-3),\n",
    "    loss=[\n",
    "        tfk.losses.BinaryCrossentropy(from_logits=True),\n",
    "        tfk.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    ],\n",
    "    loss_weights=[1.0, 0.2],\n",
    ")\n",
    "\n",
    "\n",
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_targets, \"department\": dept_targets},\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### **Mini Resnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def res_block():\n",
    "#   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tfk.Input(shape=(32, 32, 3), name='Img')\n",
    "\n",
    "# Block 1\n",
    "ten = lyrs.Conv2D(32, 3, activation='relu', padding='same')(inp)\n",
    "ten = lyrs.Conv2D(64, 3, activation='relu', padding='same')(ten)\n",
    "bl_1 = lyrs.MaxPooling2D(3)(ten)\n",
    "\n",
    "# Block 2\n",
    "ten = lyrs.Conv2D(32, 3, activation='relu', padding='same')(bl_1)\n",
    "ten = lyrs.Conv2D(64, 3, activation='relu', padding='same')(ten)\n",
    "bl_2 = lyrs.add([ten, bl_1])\n",
    "\n",
    "# Block 3\n",
    "ten = lyrs.Conv2D(32, 3, activation='relu', padding='same')(bl_2)\n",
    "ten = lyrs.Conv2D(64, 3, activation='relu', padding='same')(ten)\n",
    "bl_3 = lyrs.add([ten, bl_2])\n",
    "\n",
    "ten = lyrs.Conv2D(32, 3, activation='relu', padding='same')(bl_3)\n",
    "# ten = lyrs.Conv2D(64, 3, activation='relu', padding='same')(ten)\n",
    "ten = lyrs.GlobalAveragePooling2D()(ten)\n",
    "ten = lyrs.Dense(256, activation=acts.elu)(ten)\n",
    "ten = lyrs.Dropout(0.4)(ten)\n",
    "\n",
    "output = lyrs.Dense(10, activation='relu')(ten)\n",
    "\n",
    "Model_MiniResnet = tfk.Model(inputs= inp, outputs= output, name='ToyResnet.png')\n",
    "tfk.utils.plot_model(Model_MiniResnet, 'Mini_Resnet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_MiniResnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain, ytrain), (xtest, ytest) = tfk.datasets.cifar10.load_data()\n",
    "xtrain = xtrain.astype('float32') / 255.0\n",
    "xtest = xtest.astype('float32') / 255.0\n",
    "\n",
    "ytrain = tfk.utils.to_categorical(ytrain, 1)\n",
    "ytest = tfk.utils.to_categorical(ytest, 10)\n",
    "\n",
    "Model_MiniResnet.compile(\n",
    "    optimizer= opts.RMSprop(0.001),\n",
    "    loss= ls.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "Model_MiniResnet.fit(\n",
    "    xtrain, ytrain, epochs= 20, verbose= 2, batch_size= 32, validation_split= 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Shared Layers**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Shared layers are often used to encode inputs from similar spaces \n",
    "    (say, two different pieces of text that feature similar vocabulary). \n",
    "    They enable sharing of information across these different inputs, \n",
    "    and they make it possible to train such a model on less data. \n",
    "    If a given word is seen in one of the inputs, that will benefit the \n",
    "    processing of all inputs that pass through the shared layer.\n",
    "'''\n",
    "\n",
    "max_f = 10000\n",
    "\n",
    "# Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
    "emb_lyr = lyrs.Embedding(max_f, 128, 'uniform')\n",
    "\n",
    "# Inputs\n",
    "inp_a = tfk.Input(shape=(None, ))\n",
    "inp_b = tfk.Input(shape=(None, ))\n",
    "\n",
    "# Getting 2 sets of embeddings using the same layer\n",
    "inp_a_encoded = emb_lyr(inp_a)\n",
    "inp_b_encoded = emb_lyr(inp_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extract and reuse Nodes in graph of layers**\n",
    "\n",
    "> **Because the graph of layers you are manipulating is a static data structure, it can be accessed and inspected. This also means that you can access the activations of intermediate layers (\"nodes\" in the graph) and reuse them elsewhere -- which is very useful for something like feature extraction.**\n",
    "\n",
    "**This comes in handy for tasks like `neural style transfer`, among other things.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x261f24f5130>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature extraction from a VGG19 trained on Imagenet dataset\n",
    "vgg19 = tfk.applications.VGG19()\n",
    "\n",
    "# To extract features, we create a list of all the outputs of \n",
    "# the imtermediate Nodes in the VGG19 Model\n",
    "fea_list = [lyr.output for lyr in vgg19.layers]\n",
    "\n",
    "# Features Extraction Model!!\n",
    "fem = tfk.Model(inputs=vgg19.input, outputs=fea_list)\n",
    "fem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extend the Func-API using custom-layers**\n",
    "\n",
    "You can use the func api to create custom dense layers or create blocks of Models(reusable) using this technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Practical Use**\n",
    "\n",
    "1. **In general, the functional API is higher-level, easier and safer, and has a number of features that subclassed models do not support.**\n",
    "2. **Supports multi-input/output, complex graph topologies compared to Sequential API.**\n",
    "\n",
    "> However, model subclassing provides greater flexibility when building models that are not easily expressible as directed acyclic graphs of layers. For example, you could not implement a Tree-RNN with the functional API and would have to subclass Model directly.\n",
    "\n",
    "**For an in-depth look at the differences between the `Functional API and Model-Subclassing`, read `What are Symbolic and Imperative APIs in TensorFlow 2.0?`.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **Strengths**\n",
    "\n",
    "1. **Less verbose**\n",
    "2. **Supports complex graph-based model topologies.**\n",
    "3. **Model validation while defining its connectivity graph.(Defining the Input shape at the beginning ensures that any Model `built with functional API` will run).**\n",
    "4. **Plottable and Inspectable.**\n",
    "5. **Functional Model can be serialized or cloned.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### **Weaknesses**\n",
    "\n",
    "1. **Does not support dynamic structures(outputs a static graph datastructure.)**\n",
    "> **The functional API treats models as DAG `(Directed Acyclic Graph)` of layers. This is true for most deep learning architectures, but not all -- for example, recursive networks or Tree RNNs do not follow this assumption and cannot be implemented in the functional API.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mix n Match API styles**\n",
    "\n",
    "**Using Functional Model with Subclassed Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "units = 32\n",
    "timesteps = 10\n",
    "inp_dim = 5\n",
    "bs = 16\n",
    "\n",
    "# Define a Functional Model...\n",
    "\n",
    "Input = tfk.Input(shape=(None, units))\n",
    "lyr = lyrs.GlobalAveragePooling1D()(Input)\n",
    "Output = lyrs.Dense(1)(lyr)\n",
    "\n",
    "Model_Func = tfk.Model(\n",
    "    inputs= Input,\n",
    "    outputs= Output,\n",
    "    name='Functional_Protion'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNN(lyrs.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.p1 = lyrs.Dense(units= units, activation=acts.tanh) # First Dense Layer\n",
    "        self.p2 = lyrs.Dense(units= units, activation=acts.tanh) # Second Dense Layer\n",
    "        \n",
    "        self.classifier = Model_Func\n",
    "        \n",
    "    def call(self, input_ten):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(input_ten.shape[0], self.units))\n",
    "        \n",
    "        # Defining Logic for Custom RNN!!\n",
    "        for t in range(input_ten.shape[1]):\n",
    "            # Get the t'th tensor at each level\n",
    "            inp = input_ten[ : , t, : ]\n",
    "            ten = self.p1(inp)\n",
    "            ten = self.p2(state) + ten\n",
    "            \n",
    "            state = ten\n",
    "            outputs.append(ten)\n",
    "            \n",
    "        features = tf.stack(outputs, axis= -1)\n",
    "        \n",
    "        print(features.shape)\n",
    "        return self.classifier(features)\n",
    "\n",
    "rnnModel = CustomRNN()\n",
    "...\n",
    "# rnnModel(tf.zeros(shape=(1, timesteps, inp_dim)))\n",
    "# Last line throws an Input Shape Error!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you specify a static batch size for the inputs with the `batch_shape`\n",
    "# arg, because the inner computation of `CustomRNN` requires a static batch size\n",
    "# (when you create the `state` zeros tensor).\n",
    "\n",
    "# inputs = tfk.Input(batch_shape= (bs, timestamps, inp_dim))\n",
    "# x = lyrs.Conv1D(32, 3)(inputs)\n",
    "# outputs = CustomRNN()(x)\n",
    "\n",
    "# model = tfk.Model(inputs, outputs)\n",
    "# model\n",
    "rnn_model = CustomRNN()\n",
    "_ = rnn_model(tf.zeros((1, timesteps, input_dim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 32\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "class CustomRNN(lyrs.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.projection_1 = lyrs.Dense(units=units, activation=\"tanh\")\n",
    "        self.projection_2 = lyrs.Dense(units=units, activation=\"tanh\")\n",
    "        self.classifier = lyrs.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
    "        for t in range(inputs.shape[1]):\n",
    "            x = inputs[:, t, :]\n",
    "            h = self.projection_1(x)\n",
    "            y = h + self.projection_2(state)\n",
    "            state = y\n",
    "            outputs.append(y)\n",
    "        features = tf.stack(outputs, axis=1)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "# Note that you specify a static batch size for the inputs with the `batch_shape`\n",
    "# arg, because the inner computation of `CustomRNN` requires a static batch size\n",
    "# (when you create the `state` zeros tensor).\n",
    "inputs = tfk.Input(batch_shape=(batch_size, timesteps, input_dim))\n",
    "x = lyrs.Conv1D(32, 3)(inputs)\n",
    "outputs = CustomRNN()(x)\n",
    "\n",
    "model = tfk.Model(inputs, outputs)\n",
    "\n",
    "rnn_model = CustomRNN()\n",
    "_ = rnn_model(tf.zeros((1, 10, 5)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b8b0bc04ec3d1dc0d456e2ffa50a3bb2db1f633383799a4f8b8e1b40d883f7f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Graphs_IDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
