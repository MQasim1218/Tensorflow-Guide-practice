{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A model is, abstractly:**\n",
    "\n",
    "* A function that computes something on tensors (a forward pass)\n",
    "* Some variables that can be updated in response to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import random as ra\n",
    "import numpy as np\n",
    "import tensorboard as tb\n",
    "\n",
    "print(tb.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defining Models and Layers in TensorFlow**\n",
    "**Layers are functions with a known `mathematical structure` that can be reused and have `trainable variables`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a simple Model using tf.Module\n",
    "class Module(tf.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name= name)\n",
    "        self.tr_var = tf.Variable(5.0, name= 'train_me')\n",
    "        self.non_tr_var = tf.Variable(5.0, trainable=False , name= 'not_train')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.tr_var * x + self.non_tr_var\n",
    "\n",
    "model = Module('SimpleModel')\n",
    "model(tf.constant(3.)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable variables:  (<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>,)\n",
      "Non-Trainable variables (<tf.Variable 'not_train:0' shape=() dtype=float32, numpy=5.0>,)\n",
      "\n",
      "All variables: \n",
      "<tf.Variable 'not_train:0' shape=() dtype=float32, numpy=5.0>\n",
      "<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>\n"
     ]
    }
   ],
   "source": [
    "# Printing trainable & non_trainable variables\n",
    "print('Trainable variables: ', model.trainable_variables)\n",
    "print('Non-Trainable variables', model.non_trainable_variables)\n",
    "print()\n",
    "print('All variables: ')\n",
    "for var in model.variables:\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Creating a two-layer linear layer model made out of modules.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dense layer\n",
    "class Dense(tf.Module):\n",
    "    def __init__(self, in_fea, out_fea,name=None):\n",
    "        super().__init__(name)\n",
    "        self.wei = tf.Variable(\n",
    "            tf.random.normal([in_fea, out_fea], name= 'weights')\n",
    "        )\n",
    "        self.bias = tf.Variable(\n",
    "            tf.zeros([out_fea], name='bias')\n",
    "        )\n",
    "\n",
    "    def __call__(self, x_ten):\n",
    "        # Computation: Y = Matrix multiplication (x & weights) plus the model bias\n",
    "        # Computation: tf.nn.relu(Y)\n",
    "        y = (x_ten @ self.wei) + self.bias\n",
    "        return tf.nn.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0707111 , 0.        ],\n",
       "       [0.        , 0.38128853],\n",
       "       [0.        , 1.5856438 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sequential(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.dense1 = Dense(3, 3, 'InputLayer')\n",
    "        self.dense2 = Dense(3, 2, 'OutputLayer')\n",
    "        \n",
    "    def __call__(self, tx):\n",
    "        y = self.dense1(tx)\n",
    "        return self.dense2(y)\n",
    "\n",
    "my_model = Sequential('AI_Model')\n",
    "# Model acceptable shape [n x 3]\n",
    "my_model(tf.random.poisson([2, 3], 5.5)) \n",
    "my_model(tf.random.normal([3, 3], mean=17, stddev=3.5)).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Dense object at 0x0000021292F171C0>\n",
      "<__main__.Dense object at 0x00000212E4A477C0>\n",
      "\n",
      "var: [0. 0. 0.]\n",
      "\n",
      "var: [[-1.774076    0.59840745  0.21302606]\n",
      " [-0.3786077  -1.1040999  -0.96917003]\n",
      " [ 3.1212523  -0.48174986  1.1038833 ]]\n",
      "\n",
      "var: [0. 0.]\n",
      "\n",
      "var: [[ 0.4495117 -0.306142 ]\n",
      " [ 1.7382188  1.2382319]\n",
      " [-1.3513367  0.6562064]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing Model submodules\n",
    "for mod in my_model.submodules:\n",
    "    print(mod)\n",
    "print()\n",
    "\n",
    "# Printing model Variables\n",
    "for var in  my_model.variables: \n",
    "    print(f'var: {var.numpy()}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Waiting to create variables**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Input shape of the layers is dynamically inferered at the runtime by the size of the incoming tensor..\n",
    "class dyn_Layer(tf.Module):\n",
    "    def __init__(self, outCh, name=None):\n",
    "        super().__init__(name)\n",
    "        self.is_built = False \n",
    "        self.out_channels = outCh\n",
    "    \n",
    "    @tf.function\n",
    "    def __call__(self, tx):\n",
    "        if not self.is_built:\n",
    "            self.is_built = True\n",
    "            self.wei = tf.Variable(\n",
    "                tf.random.normal([tx.shape[-1], self.out_channels]), name='Weights'\n",
    "            )\n",
    "            self.bias = tf.Variable(\n",
    "                tf.zeros([self.out_channels], name='bias')\n",
    "            )\n",
    "        y = tx @ self.wei + self.bias\n",
    "        return tf.nn.relu(y)\n",
    "\n",
    "class dyn_SeqModel(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name)\n",
    "        self.dense1 = dyn_Layer(12, 'Input_Layer')\n",
    "        self.dense2 = dyn_Layer(3, 'Output_Layer')\n",
    "        \n",
    "    @tf.function\n",
    "    def __call__(self, tx):\n",
    "        tx = self.dense1(tx)\n",
    "        return self.dense2(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InChanels for this Model 11\n",
      "tf.Tensor(\n",
      "[[  0.        0.      235.57759]\n",
      " [  0.        0.      187.48181]\n",
      " [  0.        0.      281.76666]\n",
      " [  0.        0.      227.95454]\n",
      " [  0.        0.      257.15887]\n",
      " [  0.        0.      228.90312]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 15\n",
      "tf.Tensor(\n",
      "[[ 81.58479   48.32749  365.38065 ]\n",
      " [ 86.1093    20.791538 321.01498 ]\n",
      " [ 62.526337  35.49463  291.2561  ]\n",
      " [ 75.085625  47.113598 351.09882 ]\n",
      " [ 80.2058     0.       260.7804  ]\n",
      " [ 82.53196    8.104778 360.18277 ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 4\n",
      "tf.Tensor(\n",
      "[[  0.       165.62148   44.378143]\n",
      " [  0.       158.35931   17.842419]\n",
      " [  0.       168.06741   19.492168]\n",
      " [  0.       129.34972    0.      ]\n",
      " [  0.       171.94539   39.930893]\n",
      " [  0.       138.28317    0.      ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 1\n",
      "tf.Tensor(\n",
      "[[ 38.845837    0.         98.548706 ]\n",
      " [143.84264     0.        113.61571  ]\n",
      " [ 25.82536    12.375169   83.284775 ]\n",
      " [ 37.89099     1.3770714  98.919044 ]\n",
      " [ 34.397804   27.921349  117.14052  ]\n",
      " [ 60.9915      0.        114.88136  ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 11\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function dyn_SeqModel.__call__ at 0x00000212E3D75F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(\n",
      "[[51.704075 60.43554   0.      ]\n",
      " [52.899715 67.97682   0.      ]\n",
      " [16.239504 55.727684  0.      ]\n",
      " [33.921284 60.359394  0.      ]\n",
      " [46.161587 67.672035  0.      ]\n",
      " [45.653305 70.6726    0.      ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 3\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function dyn_SeqModel.__call__ at 0x00000212E3D75F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(\n",
      "[[11.462547  0.       52.433544]\n",
      " [42.790947  0.       33.118923]\n",
      " [28.168896  0.       75.70177 ]\n",
      " [15.937136  0.       72.01935 ]\n",
      " [15.692219  0.       38.212917]\n",
      " [59.76256   0.       45.876793]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 12\n",
      "tf.Tensor(\n",
      "[[ 31.119526   0.         9.059708]\n",
      " [110.8542     0.        27.977295]\n",
      " [ 88.05832    0.         0.      ]\n",
      " [  9.124117   0.        77.55743 ]\n",
      " [ 52.647476   0.         0.      ]\n",
      " [ 31.808712   0.         0.      ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 2\n",
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 10\n",
      "tf.Tensor(\n",
      "[[  0.        200.65608   203.06161  ]\n",
      " [  0.        199.43857   209.10948  ]\n",
      " [  0.        148.23625   163.80687  ]\n",
      " [  0.        174.70026   149.97931  ]\n",
      " [  0.        207.42181   216.52924  ]\n",
      " [  7.1828384 185.2204    203.97073  ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 13\n",
      "tf.Tensor(\n",
      "[[0.         0.         0.        ]\n",
      " [0.78588104 0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]], shape=(6, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Calling the dynamic model on different sets of inputs\n",
    "for i in range(10):\n",
    "    in_chs = ra.randint(1,15)\n",
    "    print('InChanels for this Model', in_chs)\n",
    "    model = dyn_SeqModel('AdaptiveModel')\n",
    "    tx = tf.random.uniform([6, 6], minval=16, maxval=32)\n",
    "    print(model(tx))\n",
    "\n",
    "# Our model is working...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Model results:\n",
      " [[0.         0.         0.        ]\n",
      " [0.78588104 0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "\n",
      "New Model result after restoring weights:\n",
      " [[0.         0.         0.        ]\n",
      " [0.78588104 0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "It worked\n"
     ]
    }
   ],
   "source": [
    "# Create a dir to save weights\n",
    "chk_path = 'Weights_checkpoint'\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "\n",
    "# Using this Command, the weights are stored into the file.\n",
    "checkpoint.write(chk_path)\n",
    "tf.train.list_variables(chk_path)\n",
    "\n",
    "# Creating a new Model and assigning the `SAME WEIGHTS`\n",
    "new_mod = dyn_SeqModel('Dynamic_Seq2')\n",
    "checkpoint2 = tf.train.Checkpoint(model=new_mod)\n",
    "\n",
    "# Reloading the previous weights\n",
    "checkpoint2.restore('Weights_checkpoint')\n",
    "\n",
    "# Testing the new Model on previous input, should be able to produce same output\n",
    "print(f'Previous Model results:\\n {model(tx).numpy()}\\n')\n",
    "print(f'New Model result after restoring weights:\\n {new_mod(tx).numpy()}')\n",
    "\n",
    "print(\"It worked\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving Functions + Visualization using Tensorboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 81.25644    0.         0.      ]\n",
      " [ 16.028282   0.         0.      ]\n",
      " [ 83.058716   0.         0.      ]\n",
      " [130.58557    0.         0.      ]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# setting up logging\n",
    "timest = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logs_dir = 'logs/func/%s' % timest\n",
    "writer = tf.summary.create_file_writer(logs_dir)\n",
    "\n",
    "# Create new model to get fresh trace\n",
    "SeqModel = dyn_SeqModel('Traced_Model')\n",
    "tf.summary.trace_on(graph= True)\n",
    "tf.profiler.experimental.start(logs_dir)\n",
    "\n",
    "# Only call one tf.function while tracing\n",
    "print(SeqModel(tf.random.uniform(shape=[4, 9], minval= 50, maxval= 70)))\n",
    "\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name= 'Function Trace',\n",
    "        step= 0,\n",
    "        profiler_outdir= logs_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Starting Tensorboard to visualize tracing results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logs/func\n",
    "\n",
    "# Masha-Allah it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Creating a saved Model**\n",
    "> The recommended way of sharing completely trained models is to use SavedModel. SavedModel contains both a collection of functions and a collection of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SavedModel\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the Model.. A separate directory is created to store the saved Model \n",
    "tf.saved_model.save(SeqModel, 'SavedModel')\n",
    "\n",
    "# Reloading the saved Model. It is in Graph format with no knowledge of internal TensorFlow code.\n",
    "SeqMod2 = tf.saved_model.load('SavedModel')\n",
    "\n",
    "# Checking if the loaded model is an object of Sequential class \n",
    "isinstance(SeqMod2, dyn_SeqModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **The new model can only work with `pre-defined signatures` (input shape && data-type). It `cannot` be altered to perform on new signatures like Python Code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[19.372972 24.694708 23.173527 18.843626 26.308035 31.051912]\n",
      " [18.846718 28.704638 18.931368 27.646376 24.772425 25.513197]\n",
      " [19.655659 24.778566 30.359911 17.207092 21.801762 18.40712 ]\n",
      " [26.617722 29.929058 22.761803 27.37734  22.628262 22.63971 ]\n",
      " [30.373575 24.196802 26.882948 27.649286 19.97745  30.08856 ]\n",
      " [16.944263 23.143307 20.68682  25.31832  29.440924 24.941862]], shape=(6, 6), dtype=float32)\n",
      "[[4.6377244  0.         0.        ]\n",
      " [3.25116    0.         0.        ]\n",
      " [1.2656194  0.         0.        ]\n",
      " [5.615899   0.         0.13157356]]\n",
      "Error Raised due to incompatible input signature!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(tx)\n",
    "    # Sending in a known signature\n",
    "    print(SeqMod2(tf.random.uniform([4,9])).numpy())\n",
    "    \n",
    "    # Sending an unknown argument\n",
    "    print(SeqMod2(tf.constant(1.0)))\n",
    "    \n",
    "except:\n",
    "    print(\"Error Raised due to incompatible input signature!!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Keras Models and Layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Keras Layers**\n",
    "> **Keras Layers as based on TF.Module. One can easily swap out TF.Module with Keras.layers.Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[ 0.      ,  0.      ,  0.      , 42.338474,  0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , 27.794685,  0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , 43.56392 ,  0.      ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KerasDense(tf.keras.layers.Layer):\n",
    "    # In_features defines the number of rows for the Layer_Weights Matrix \n",
    "    # Out_features determines the number of columns for the Weights Matrix\n",
    "    def __init__(self, in_features, out_features, **args):\n",
    "        super().__init__(**args)\n",
    "        self.w = tf.Variable(\n",
    "            tf.random.normal([in_features, out_features], name='Lyr_Weights')\n",
    "        )\n",
    "        # Here we are setting the model bias to zero (will try with identity matrix soon)..\n",
    "        self.b = tf.Variable(\n",
    "            tf.zeros([out_features], name='Lyr_Bias')\n",
    "        )\n",
    "    @tf.function\n",
    "    def call(self, ten_x):\n",
    "        return tf.nn.relu((ten_x @ self.w) + self.b)\n",
    "\n",
    "\n",
    "denselayer = KerasDense(6, 5, name=\"Simple_Layer\")\n",
    "denselayer(tf.random.uniform([3, 6], minval=10, maxval=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **The build step**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Variables:  []\n",
      "Input_features: 4\n",
      "tf.Tensor(\n",
      "[[0.99878025 0.99550277 0.96360517 0.00484243]\n",
      " [0.96552706 0.99653614 0.9768597  0.00450647]\n",
      " [0.93478215 0.8688572  0.99999976 0.23803753]], shape=(3, 4), dtype=float32)\n",
      "highest Probability tensor: 10\n"
     ]
    }
   ],
   "source": [
    "# Adding the build function to out Keras based Layer\n",
    "# Called exactly once.\n",
    "# Used to adapt Variables to the input shape\n",
    "\n",
    "class dyn_KerasDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_chs, **kwargs):\n",
    "        # in the constructor, only call \n",
    "        # the parent constructor and \n",
    "        # define the output-channels\n",
    "        super().__init__(**kwargs)\n",
    "        self.out_features = out_chs\n",
    "        \n",
    "    def build(self, in_shape):\n",
    "        print(f'Input_features: {in_shape[-1]}')\n",
    "        self.w = tf.Variable(\n",
    "            tf.random.normal([in_shape[-1], self.out_features]), \n",
    "            name='Lyr_Weights'\n",
    "        )\n",
    "        self.b = tf.Variable(\n",
    "            tf.zeros([self.out_features]), \n",
    "            name='Lyr_bias'\n",
    "        )\n",
    "    \n",
    "    def call(self, ten_x):\n",
    "        y = (ten_x @ self.w) + self.b\n",
    "        return tf.nn.sigmoid(y)\n",
    "    \n",
    "# Instantiating a flexible layer\n",
    "flexible_dense = dyn_KerasDense(out_chs= 4)\n",
    "# Checking variables to ensure none have been initialized by now \n",
    "print(\"Printing Variables: \",flexible_dense.variables)\n",
    "\n",
    "# Call the layer and recheck the variables\n",
    "# Calling the layer implicitly calls build method\n",
    "# which adapts the Layer to the incoming input_shape \n",
    "\n",
    "# For incoming tensor (m x n) && weights Matrix (in_F x out_F)\n",
    "# Expected Output shape (m x out_features)\n",
    "tx = tf.constant(\n",
    "    [\n",
    "        [2., 3., 4., 7.],\n",
    "        [8., 6., 3., 5.],\n",
    "        [5., 2., 7., 1.]\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_ten = flexible_dense(tx)\n",
    "print(output_ten)\n",
    "highest_prob = np.argmax(output_ten)\n",
    "print(f'highest Probability tensor: {highest_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Layer result for 5 x 4 Matrix\n",
      "[[0.6629041  0.608057   0.81009364 0.40424508]\n",
      " [0.6571983  0.58733976 0.69261706 0.40471333]\n",
      " [0.7110011  0.65120465 0.69964397 0.34042174]\n",
      " [0.5613028  0.5708911  0.5281627  0.43305972]\n",
      " [0.7324807  0.6344897  0.68442184 0.35309082]] \n",
      "\n",
      "Keras Layer result for 5 x 5 Matrix\n",
      "Failed to execute\n",
      "Following error encountered:  In[0] mismatch In[1] shape: 5 vs. 4: [5,5] [4,4] 0 0 [Op:MatMul]\n"
     ]
    }
   ],
   "source": [
    "# Layers instantiated via build method only accept \n",
    "# certian types of inputs\n",
    "\n",
    "try:\n",
    "    # the weights have dims 4 x 4, thus any tensor \n",
    "    # with shape m x 4 is acceptable\n",
    "    print(\"Keras Layer result for 5 x 4 Matrix\")\n",
    "    tx2 = tf.random.uniform([5, 4])\n",
    "    print(flexible_dense(tx2).numpy(), '\\n')\n",
    "    \n",
    "    print('Keras Layer result for 5 x 5 Matrix')\n",
    "    tx3 = tf.random.normal([5, 5])\n",
    "    print(flexible_dense(tx3).numpy(), '\\n')\n",
    "    \n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print('Failed to execute\\nFollowing error encountered: ', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Keras Models**\n",
    "> **We'll build Basic Model based Keras.Model using our perviously created layers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqModel(tf.keras.Model):\n",
    "    def __init__(self, name=None, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d1 = dyn_KerasDense(out_chs=8)\n",
    "        self.d2 = dyn_KerasDense(out_chs=4)\n",
    "        \n",
    "    def call(self, tx):\n",
    "        y1 = self.d1(tx)\n",
    "        y2 = self.d2(y1)\n",
    "        return tf.nn.softmax(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_features: 6\n",
      "Input_features: 8\n",
      "11\n",
      "18\n",
      "10\n",
      "27\n",
      "27\n",
      "7\n",
      "5\n",
      "5\n",
      "31\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# calling Model on set of tensors\n",
    "in_ten = tf.random.normal([10, 8, 6], mean=0, stddev=5)\n",
    "# print(tf.cast(in_ten, tf.int32))\n",
    "KerasModel = SeqModel(name='Sequential_Model')\n",
    "l = []\n",
    "for tx in in_ten:\n",
    "    l.append(KerasModel(tx))\n",
    "    \n",
    "Prob = [lambda x=x: np.argmax(x) for x in l]\n",
    "for i in Prob:\n",
    "    print(i())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77475536  0.7236223   0.37438998  0.78802305  1.0814286   1.5277098\n",
      "   1.153451   -0.25924844]\n",
      " [-2.1428092   2.1957579  -0.28224364  1.9325789  -0.13117966  0.43129703\n",
      "  -0.30782795 -1.6924505 ]\n",
      " [-0.57624555  0.33753073  1.5933595   0.5462931   0.42614013 -1.1992669\n",
      "   0.57005596  1.2030897 ]\n",
      " [-0.11192408 -1.7380764  -1.047696   -0.3655173  -0.7205488   0.84757954\n",
      "  -1.2282318  -0.8881277 ]\n",
      " [ 0.6300752   0.16339798 -0.0252235  -1.1661518   0.93930393 -0.00492984\n",
      "  -0.359546    0.01522431]\n",
      " [ 0.6519948  -0.0159054  -0.479939   -1.1294913   0.4358606  -0.7759148\n",
      "  -1.1337433   0.75997394]] \n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "[[ 0.20040578  0.796959   -0.88844216  0.92749864]\n",
      " [-1.3488828  -0.73018736  2.3114796   0.33971065]\n",
      " [-0.1409341  -0.6921915  -1.2638459   0.15682694]\n",
      " [ 0.33052132  0.1041619   0.982661    1.5454324 ]\n",
      " [-1.1647314   0.2276119  -0.6524512   0.47919834]\n",
      " [ 1.3130949   1.1562636  -0.22116068 -0.68737185]\n",
      " [ 1.4462749   0.66544473 -0.3652558   0.97658545]\n",
      " [ 1.1205233   0.38773286  0.36875522 -0.01785856]] \n",
      "\n",
      "[0. 0. 0. 0.] \n",
      "\n",
      "\n",
      "<__main__.dyn_KerasDense object at 0x000002129478EA90>\n",
      "<__main__.dyn_KerasDense object at 0x00000212930533A0>\n"
     ]
    }
   ],
   "source": [
    "for var in KerasModel.variables:\n",
    "    print(var.numpy(), '\\n')\n",
    "    \n",
    "print()\n",
    "for mod in KerasModel.submodules:\n",
    "    print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dyn__keras_dense_62 (dyn_Ker multiple                  56        \n",
      "_________________________________________________________________\n",
      "dyn__keras_dense_63 (dyn_Ker multiple                  36        \n",
      "=================================================================\n",
      "Total params: 92\n",
      "Trainable params: 92\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "KerasModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving Keras Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`Sonnet`: Alternate deep-learning API for building ML Models**\n",
    "> **By DeepMind,**\n",
    "> **Based on tf.Module**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "445be380edc556d8a8859931574c9be2b357dc49fbb96280944087ec4ff5e718"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('OCR': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
