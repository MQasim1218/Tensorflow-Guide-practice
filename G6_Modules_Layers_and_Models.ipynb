{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A model is, abstractly:**\n",
    "\n",
    "* A function that computes something on tensors (a forward pass)\n",
    "* Some variables that can be updated in response to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import random as ra\n",
    "import tensorboard as tb\n",
    "\n",
    "print(tb.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defining Models and Layers in TensorFlow**\n",
    "**Layers are functions with a known `mathematical structure` that can be reused and have `trainable variables`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a simple Model using tf.Module\n",
    "class Module(tf.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name= name)\n",
    "        self.tr_var = tf.Variable(5.0, name= 'train_me')\n",
    "        self.non_tr_var = tf.Variable(5.0, trainable=False , name= 'not_train')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.tr_var * x + self.non_tr_var\n",
    "\n",
    "model = Module('SimpleModel')\n",
    "model(tf.constant(3.)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable variables:  (<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>,)\n",
      "Non-Trainable variables (<tf.Variable 'not_train:0' shape=() dtype=float32, numpy=5.0>,)\n",
      "\n",
      "All variables: \n",
      "<tf.Variable 'not_train:0' shape=() dtype=float32, numpy=5.0>\n",
      "<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>\n"
     ]
    }
   ],
   "source": [
    "# Printing trainable & non_trainable variables\n",
    "print('Trainable variables: ', model.trainable_variables)\n",
    "print('Non-Trainable variables', model.non_trainable_variables)\n",
    "print()\n",
    "print('All variables: ')\n",
    "for var in model.variables:\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Creating a two-layer linear layer model made out of modules.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dense layer\n",
    "class Dense(tf.Module):\n",
    "    def __init__(self, in_fea, out_fea,name=None):\n",
    "        super().__init__(name)\n",
    "        self.wei = tf.Variable(\n",
    "            tf.random.normal([in_fea, out_fea], name= 'weights')\n",
    "        )\n",
    "        self.bias = tf.Variable(\n",
    "            tf.zeros([out_fea], name='bias')\n",
    "        )\n",
    "\n",
    "    def __call__(self, x_ten):\n",
    "        # Computation: Y = Matrix multiplication (x & weights) plus the model bias\n",
    "        # Computation: tf.nn.relu(Y)\n",
    "        y = (x_ten @ self.wei) + self.bias\n",
    "        return tf.nn.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.620003, 99.03945 ],\n",
       "       [12.422647, 99.27185 ],\n",
       "       [15.690988, 63.555214]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sequential(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.dense1 = Dense(3, 3, 'InputLayer')\n",
    "        self.dense2 = Dense(3, 2, 'OutputLayer')\n",
    "        \n",
    "    def __call__(self, tx):\n",
    "        y = self.dense1(tx)\n",
    "        return self.dense2(y)\n",
    "\n",
    "my_model = Sequential('AI_Model')\n",
    "# Model acceptable shape [n x 3]\n",
    "my_model(tf.random.poisson([2, 3], 5.5)) \n",
    "my_model(tf.random.normal([3, 3], mean=17, stddev=3.5)).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Dense object at 0x000001DC3B9FFCA0>\n",
      "<__main__.Dense object at 0x000001DC6A8EA0A0>\n",
      "\n",
      "var: [0. 0. 0.]\n",
      "\n",
      "var: [[ 2.2870154   0.00319489  0.13522476]\n",
      " [ 0.29424453  0.25586474 -0.30452242]\n",
      " [ 0.37787178  0.84810615 -0.07773181]]\n",
      "\n",
      "var: [0. 0.]\n",
      "\n",
      "var: [[-0.4141421   1.5877358 ]\n",
      " [ 1.5809528   0.6924127 ]\n",
      " [-0.3139612  -0.32010743]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing Model submodules\n",
    "for mod in my_model.submodules:\n",
    "    print(mod)\n",
    "print()\n",
    "\n",
    "# Printing model Variables\n",
    "for var in  my_model.variables: \n",
    "    print(f'var: {var.numpy()}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Waiting to create variables**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Input shape of the layers is dynamically inferered at the runtime by the size of the incoming tensor..\n",
    "class dyn_Layer(tf.Module):\n",
    "    def __init__(self, outCh, name=None):\n",
    "        super().__init__(name)\n",
    "        self.is_built = False \n",
    "        self.out_channels = outCh\n",
    "    \n",
    "    @tf.function\n",
    "    def __call__(self, tx):\n",
    "        if not self.is_built:\n",
    "            self.is_built = True\n",
    "            self.wei = tf.Variable(\n",
    "                tf.random.normal([tx.shape[-1], self.out_channels]), name='Weights'\n",
    "            )\n",
    "            self.bias = tf.Variable(\n",
    "                tf.zeros([self.out_channels], name='bias')\n",
    "            )\n",
    "        \n",
    "        y = tx @ self.wei + self.bias\n",
    "        return tf.nn.relu(y)\n",
    "    \n",
    "class dyn_SeqModel(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name)\n",
    "        self.dense1 = dyn_Layer(12, 'Input_Layer')\n",
    "        self.dense2 = dyn_Layer(3, 'Output_Layer')\n",
    "        \n",
    "    @tf.function\n",
    "    def __call__(self, tx):\n",
    "        tx = self.dense1(tx)\n",
    "        return self.dense2(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InChanels for this Model 5\n",
      "tf.Tensor(\n",
      "[[32.586563 28.136518 41.810143]\n",
      " [37.952003 33.553192 52.098286]\n",
      " [43.578575 51.636368 56.145725]\n",
      " [21.4276    0.       48.96453 ]\n",
      " [30.29971  37.51879  62.928024]\n",
      " [41.38082  11.17831  61.114265]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 7\n",
      "tf.Tensor(\n",
      "[[100.25137    19.110264  144.00226  ]\n",
      " [ 85.05576    16.723856  162.82172  ]\n",
      " [ 39.593456    4.2811165  77.2881   ]\n",
      " [ 78.98489    12.434948   89.01366  ]\n",
      " [117.83304    28.318377  140.31369  ]\n",
      " [102.60702     0.        189.57448  ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 7\n",
      "tf.Tensor(\n",
      "[[  0.         0.        70.673706]\n",
      " [  0.         0.        97.84123 ]\n",
      " [  0.         0.        69.60656 ]\n",
      " [  0.         0.       135.0037  ]\n",
      " [  0.         0.       112.29971 ]\n",
      " [  0.         0.       107.42939 ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 6\n",
      "tf.Tensor(\n",
      "[[ 79.274      0.        88.99805 ]\n",
      " [ 87.23201    0.        78.11565 ]\n",
      " [ 59.740997   0.        91.46654 ]\n",
      " [ 92.00441    0.        78.62145 ]\n",
      " [137.9115     0.        71.73561 ]\n",
      " [147.29074    0.        88.82295 ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 8\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function dyn_SeqModel.__call__ at 0x000001DC3BA0F670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(\n",
      "[[ 0.        0.       64.35785 ]\n",
      " [ 0.        0.       37.245213]\n",
      " [ 0.        0.       58.618557]\n",
      " [ 0.        0.       42.71426 ]\n",
      " [ 0.        0.       93.784584]\n",
      " [ 0.        0.       90.954124]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 12\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function dyn_SeqModel.__call__ at 0x000001DC3BA0F670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(\n",
      "[[5.5244446e-02 0.0000000e+00 4.9891445e+01]\n",
      " [0.0000000e+00 0.0000000e+00 6.1652096e+01]\n",
      " [8.0390930e-01 0.0000000e+00 5.6319801e+01]\n",
      " [1.1484673e+01 0.0000000e+00 5.1666451e+01]\n",
      " [0.0000000e+00 0.0000000e+00 6.5205513e+01]\n",
      " [0.0000000e+00 0.0000000e+00 6.5771049e+01]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 2\n",
      "tf.Tensor(\n",
      "[[  0.      199.07596   0.     ]\n",
      " [  0.      248.73834   0.     ]\n",
      " [  0.      165.6095    0.     ]\n",
      " [  0.      202.11008   0.     ]\n",
      " [  0.      189.7569    0.     ]\n",
      " [  0.      193.3366    0.     ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 6\n",
      "tf.Tensor(\n",
      "[[59.832863    0.         49.61608   ]\n",
      " [65.01853     0.          0.37082958]\n",
      " [39.25207     0.         70.98777   ]\n",
      " [58.906612    0.         63.570724  ]\n",
      " [54.177143    0.         46.964466  ]\n",
      " [47.424465    0.         59.838684  ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 14\n",
      "tf.Tensor(\n",
      "[[ 16.146149 139.0615   141.63571 ]\n",
      " [  0.        97.65971  104.434616]\n",
      " [ 29.238777 134.58098  133.00117 ]\n",
      " [  0.       105.8472   111.48464 ]\n",
      " [ 74.012    127.6746   124.04936 ]\n",
      " [  8.150652 141.89162  141.09296 ]], shape=(6, 3), dtype=float32)\n",
      "InChanels for this Model 4\n",
      "tf.Tensor(\n",
      "[[0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [5.551487 0.       0.      ]\n",
      " [0.       0.       0.      ]], shape=(6, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Calling the dynamic model on different sets of inputs\n",
    "for i in range(10):\n",
    "    in_chs = ra.randint(1,15)\n",
    "    print('InChanels for this Model', in_chs)\n",
    "    model = dyn_SeqModel('AdaptiveModel')\n",
    "    tx = tf.random.uniform([6, 6], minval=16, maxval=32)\n",
    "    print(model(tx))\n",
    "\n",
    "# Our model is working...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Model results:\n",
      " [[0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [5.551487 0.       0.      ]\n",
      " [0.       0.       0.      ]]\n",
      "\n",
      "New Model result after restoring weights:\n",
      " [[0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [0.       0.       0.      ]\n",
      " [5.551487 0.       0.      ]\n",
      " [0.       0.       0.      ]]\n",
      "It worked\n"
     ]
    }
   ],
   "source": [
    "# Create a dir to save weights\n",
    "chk_path = 'Weights_checkpoint'\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "\n",
    "# Using this Command, the weights are stored into the file.\n",
    "checkpoint.write(chk_path)\n",
    "tf.train.list_variables(chk_path)\n",
    "\n",
    "# Creating a new Model and assigning the `SAME WEIGHTS`\n",
    "new_mod = dyn_SeqModel('Dynamic_Seq2')\n",
    "checkpoint2 = tf.train.Checkpoint(model=new_mod)\n",
    "\n",
    "# Reloading the previous weights\n",
    "checkpoint2.restore('Weights_checkpoint')\n",
    "\n",
    "# Testing the new Model on previous input, should be able to produce same output\n",
    "print(f'Previous Model results:\\n {model(tx).numpy()}\\n')\n",
    "print(f'New Model result after restoring weights:\\n {new_mod(tx).numpy()}')\n",
    "\n",
    "print(\"It worked\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving Functions + Visualization using Tensorboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up logging\n",
    "timest = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logs_dir = 'logs/func/%s' % timest\n",
    "writer = tf.summary.create_file_writer(logs_dir)\n",
    "\n",
    "# Create new model to get fresh trace\n",
    "SeqModel = dyn_SeqModel('Traced_Model')\n",
    "tf.summary.trace_on(graph= True)\n",
    "tf.profiler.experimental.start(logs_dir)\n",
    "\n",
    "# Only call one tf.function while tracing\n",
    "print(SeqModel(tf.random.uniform(shape=[4, 9], minval= 50, maxval= 70)))\n",
    "\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name= 'Function Trace',\n",
    "        step= 0,\n",
    "        profiler_outdir= logs_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Starting Tensorboard to visualize tracing results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logs/func\n",
    "\n",
    "# Masha-Allah it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Creating a saved Model**\n",
    "> The recommended way of sharing completely trained models is to use SavedModel. SavedModel contains both a collection of functions and a collection of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SavedModel\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the Model.. A separate directory is created to store the saved Model \n",
    "tf.saved_model.save(SeqModel, 'SavedModel')\n",
    "\n",
    "# Reloading the saved Model. It is in Graph format with no knowledge of internal TensorFlow code.\n",
    "SeqMod2 = tf.saved_model.load('SavedModel')\n",
    "\n",
    "# Checking if the loaded model is an object of Sequential class \n",
    "isinstance(SeqMod2, dyn_SeqModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **The new model can only work with `pre-defined signatures` (input shape && data-type). It `cannot` be altered to perform on new signatures like Python Code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[24.571182 27.901814 16.977583 23.294868 26.34833  25.91249 ]\n",
      " [21.052631 27.666346 17.133547 25.036602 19.52958  17.714447]\n",
      " [17.855251 21.62644  28.017302 26.501816 26.499147 21.345549]\n",
      " [26.773119 27.076963 24.35641  18.492205 25.63773  24.267067]\n",
      " [20.255909 18.208706 16.620312 18.280846 19.88789  25.348614]\n",
      " [29.893362 26.71646  31.23438  22.951586 27.147898 28.046225]], shape=(6, 6), dtype=float32)\n",
      "[[0.37259245 2.5588136  0.5820939 ]\n",
      " [2.8372762  2.243465   0.        ]\n",
      " [5.401466   3.54496    0.        ]\n",
      " [5.1961412  1.6135643  2.0946856 ]]\n",
      "Some Error Raised!!\n",
      "{e}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(tx)\n",
    "    # Sending in a known signature\n",
    "    print(SeqMod2(tf.random.uniform([4,9])).numpy())\n",
    "    \n",
    "    # Sending an unknown argument\n",
    "    print(SeqMod2(tf.constant(1.0)))\n",
    "    \n",
    "except:\n",
    "    print(\"Error Raised due to incompatible input signature!!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Keras Models and Layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Keras Layers**\n",
    "> **Keras Layers as based on TF.Module. One can easily swap out TF.Module with Keras.layers.Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[ 0.       , 10.594601 , 19.097565 ,  0.       ,  0.       ],\n",
       "       [ 0.       ,  1.3583794, 23.31422  ,  5.3604546,  0.       ],\n",
       "       [ 0.       ,  6.355938 , 24.87617  ,  1.0125513,  0.       ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KerasDense(tf.keras.layers.Layer):\n",
    "    # In_features defines the number of rows for the Layer_Weights Matrix \n",
    "    # Out_features determines the number of columns for the Weights Matrix\n",
    "    def __init__(self, in_features, out_features, **args):\n",
    "        super().__init__(**args)\n",
    "        self.w = tf.Variable(\n",
    "            tf.random.normal([in_features, out_features], name='Lyr_Weights')\n",
    "        )\n",
    "        # Here we are setting the model bias to zero (will try with identity matrix soon)..\n",
    "        self.b = tf.Variable(\n",
    "            tf.zeros([out_features], name='Lyr_Bias')\n",
    "        )\n",
    "    @tf.function\n",
    "    def call(self, ten_x):\n",
    "        return tf.nn.relu((ten_x @ self.w) + self.b)\n",
    "\n",
    "\n",
    "denselayer = KerasDense(6, 5, name=\"Simple_Layer\")\n",
    "denselayer(tf.random.uniform([3, 6], minval=10, maxval=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **The build step**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Keras Models**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving Keras Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`Sonnet`: Alternate deep-learning API for building ML Models**\n",
    "> **By DeepMind,**\n",
    "> **Based on tf.Module**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "445be380edc556d8a8859931574c9be2b357dc49fbb96280944087ec4ff5e718"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('OCR': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
