{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    In this guide, we'll learn \\n        1. how TensorFlow allows you to make simple changes to your code to get graphs, \\n        2. how graphs are stored and represented, \\n        3. and how you can use them to accelerate your models.      \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    In this guide, we'll learn \n",
    "        1. how TensorFlow allows you to make simple changes to your code to get graphs, \n",
    "        2. how graphs are stored and represented, \n",
    "        3. and how you can use them to accelerate your models.      \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TF.function**\n",
    "> * **`tf.function`: allows us to switch from eager-function to graph function**\n",
    "> * **`EagerExecution`: TensorFlow operations are executed by Python, operation by operation, and returning results back to Python**\n",
    "> * **`GraphExecution:` Graph execution means that tensor computations are executed as a TensorFlow graph**\n",
    "\n",
    "#### **TF.graph**\n",
    "> * **Graphs are data structures that contain a set of `tf.Operation` objects, which represent units of computation and `tf.Tensor` objects, which represent the units of data that flow between operations.**\n",
    "> * **Graphs increases Model `portability` outside of Python and increases `performance`.**\n",
    "> * **Portability: environments without Python interpreter, eg mobile apps, embedded devices, and backend servers**\n",
    "> * **TensorFlow uses graphs as the `format for saved models` when it exports them from Python.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`Graph Optimization`:**\n",
    "> * **`Constant Folding`: Statically infer the value of tensors by folding constant nodes in computation.**\n",
    "> * **Separate sub-parts of a computation that are independent and split them between `threads or devices`.**\n",
    "> * **Simplify arithmetic operations by eliminating common sub-expressions.**\n",
    "\n",
    "**There is an entire optimization system, `Grappler`, to perform this and other speedups.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit as tit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Taking advantage of Graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Tensor T1\n",
      " [[1.  4.  5.5]]\n",
      "\n",
      "Printing Tensor T2\n",
      " [[33.822636 10.392761]\n",
      " [26.041779 32.228683]\n",
      " [20.323357 30.947838]]\n",
      "\n",
      "Printing Tensor T3\n",
      " [[-1.4044924   0.42913023]]\n",
      "\n",
      "Result of Python function:  [[248.36371 309.94974]] \n",
      "\n",
      "Result of TF.Graph function:  [[248.36371 309.94974]] \n",
      "\n",
      "The function failed\n"
     ]
    }
   ],
   "source": [
    "# Defining a regular python function\n",
    "def func(x, y, b):\n",
    "    ten = tf.matmul(x, y)\n",
    "    ten = ten + b\n",
    "    return ten\n",
    "\n",
    "# convert regular function to tf.graph\n",
    "graph_fn = tf.function(func)\n",
    "\n",
    "\n",
    "# Creating test tensors\n",
    "t1 = tf.constant([[1., 4., 5.5]]) # 1 x 3\n",
    "t2 = tf.random.uniform(shape=(3, 2), minval=10, maxval=50, dtype=tf.float32, seed=25) # 3 x 3\n",
    "t3 = tf.random.normal(shape=(1,2)) # 1 x 3 \n",
    "print('Printing Tensor T1\\n', t1.numpy())\n",
    "print()\n",
    "print('Printing Tensor T2\\n', t2.numpy())\n",
    "print()\n",
    "print('Printing Tensor T3\\n', t3.numpy())\n",
    "print()\n",
    "\n",
    "regular_fn_result = func(t1,t2,t3)\n",
    "print('Result of Python function: ', regular_fn_result.numpy(), '\\n')\n",
    "\n",
    "graph_fn_result = graph_fn(t1, t2, t3)\n",
    "print('Result of TF.Graph function: ', graph_fn_result.numpy(), '\\n')\n",
    "\n",
    "# Checking equility of the results\n",
    "try:\n",
    "    assert(regular_fn_result == graph_fn_result)\n",
    "except:\n",
    "    print('The function failed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[40.5]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def inner_fn(t1,t2,t3):\n",
    "    ten = tf.matmul(t1,t2)\n",
    "    ten = ten * t3\n",
    "    return ten\n",
    "# Using @tf.function directly to create graphs\n",
    "@tf.function\n",
    "def outr_fn(x):\n",
    "    t1 = tf.constant([[3.],[6.]])\n",
    "    t2 = tf.constant(4.5)\n",
    "\n",
    "    # tf.function applies to a function and all other functions it calls\n",
    "    return inner_fn(x, t1, t2)\n",
    "        \n",
    "# Calling the tf function\n",
    "t1 = tf.ones(shape=(1, 2))\n",
    "print(outr_fn(t1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Python funtions to graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Branch result: 10\n",
      "Second Branch result: 0\n"
     ]
    }
   ],
   "source": [
    "def simple_relu(x):\n",
    "    if tf.greater(x, 0):\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# `graph_relu` is a TensorFlow `Function` that wraps `simple_relu`\n",
    "graph_relu = tf.function(simple_relu)\n",
    "print(f'First Branch result: {graph_relu(tf.constant(10)).numpy()}')\n",
    "print(f'Second Branch result: {graph_relu(tf.constant(-10)).numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__simple_relu(x):\n",
      "    with ag__.FunctionScope('simple_relu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (do_return, retval_)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal do_return, retval_\n",
      "            (do_return, retval_) = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal do_return, retval_\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = ag__.ld(x)\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal do_return, retval_\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = 0\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "        ag__.if_stmt(ag__.converted_call(ag__.ld(tf).greater, (ag__.ld(x), 0), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the graphs code using tf.autograph.to_code()\n",
    "print(tf.autograph.to_code(simple_relu))\n",
    "\n",
    "# Easy to print, impossible to read!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the actual graph of the function\n",
      "node {\n",
      "  name: \"x\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"_user_specified_name\"\n",
      "    value {\n",
      "      s: \"x\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater\"\n",
      "  op: \"Greater\"\n",
      "  input: \"x\"\n",
      "  input: \"Greater/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond\"\n",
      "  op: \"StatelessIf\"\n",
      "  input: \"Greater\"\n",
      "  input: \"x\"\n",
      "  attr {\n",
      "    key: \"Tcond\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tin\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tout\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_BOOL\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_lower_using_switch_merge\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_read_only_resource_inputs\"\n",
      "    value {\n",
      "      list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"else_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_false_48\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"output_shapes\"\n",
      "    value {\n",
      "      list {\n",
      "        shape {\n",
      "        }\n",
      "        shape {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"then_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_true_47\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond/Identity_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_true_47\"\n",
      "      input_arg {\n",
      "        name: \"cond_identity_1_x\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond_identity_1_x\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity_1\"\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_false_48\"\n",
      "      input_arg {\n",
      "        name: \"cond_placeholder\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_1\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_1\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_2\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_2\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_3\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_3\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_3:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_4\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Const_4\"\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_4:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      experimental_debug_info {\n",
      "        original_node_names: \"cond/Identity_1\"\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 808\n",
      "  min_consumer: 12\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Graph generated from the `simple_relu` function\n",
    "print(f'Printing the actual graph of the function')\n",
    "print(graph_relu.get_concrete_function(tf.constant(2)).graph.as_graph_def())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Polymorphism: One funtion, many graphs**\n",
    "> * **Each time you invoke a Function with new dtypes and shapes in its arguments, Function creates a new `tf.Graph` for the new arguments.** \n",
    "> * **The dtypes and shapes of a tf.Graph's inputs are known as an `input signature`.**\n",
    "> * **The Function stores the tf.Graph corresponding to that signature in a `ConcreteFunction`. A ConcreteFunction is a wrapper around a tf.Graph.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the top 2 examples, a new graph is instantaited to back the operation as a new signature is received\n",
      "\n",
      "Python code!!\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "Python code!!\n",
      "tf.Tensor(\n",
      "[[False]\n",
      " [ True]], shape=(2, 1), dtype=bool)\n",
      "\n",
      "No new graph is instantiated as the function has already seen the input signatures\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[ True]\n",
      " [False]], shape=(2, 1), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_relu(x):\n",
    "    print('Python code!!')\n",
    "    return tf.greater(0., x)\n",
    "\n",
    "print('In the top 2 examples, a new graph is instantaited to back the operation as a new signature is received\\n')\n",
    "print(my_relu(tf.constant(3.)))\n",
    "print(my_relu(\n",
    "    tf.constant([\n",
    "        [3.], [-5.]\n",
    "    ])\n",
    "))\n",
    "print()\n",
    "\n",
    "print('No new graph is instantiated as the function has already seen the input signatures')\n",
    "print(my_relu(tf.constant(3.)))\n",
    "print(my_relu(\n",
    "    tf.constant([\n",
    "        [-12.], [10]\n",
    "    ])\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    bool Tensor, shape=()\n",
      "\n",
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(2, 1)\n",
      "  Returns:\n",
      "    bool Tensor, shape=(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(my_relu.pretty_printed_concrete_signatures()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using TF.function**\n",
    "**`Getting Function to work properly`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Graph Exec vs Eager Exec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1:\n",
      " [[2 8]\n",
      " [8 4]]\n",
      "Tensor 2:\n",
      " [[11  7]\n",
      " [ 6  8]]\n",
      "\n",
      "Running Eagerly\n",
      "Mean-squared-error for the above tensors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.934187"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a mean-squared-err func replica\n",
    "@tf.function\n",
    "def MSE_fn(y_tr, y_pr):\n",
    "    print(\"Running Eagerly\")\n",
    "    sq_diff = tf.pow(y_tr - y_pr,2)\n",
    "    return tf.reduce_mean(sq_diff)\n",
    "\n",
    "# Declaring constants\n",
    "t1 = tf.random.normal(shape= [2, 2], mean=7, stddev=2.5, dtype=tf.float32)\n",
    "t2 = tf.random.uniform(shape= [2, 2], minval=5, maxval= 13, dtype=tf.float32)\n",
    "\n",
    "print(f'Tensor 1:\\n {tf.cast(t1, tf.int32)}')\n",
    "print(f'Tensor 2:\\n {tf.cast(t2, tf.int32)}\\n')\n",
    "\n",
    "ten = MSE_fn(t1, t2)\n",
    "print('Mean-squared-error for the above tensors')\n",
    "ten.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Eagerly\n",
      "23.934187\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    To verify that your Function's graph is doing the same computation \n",
    "    as its equivalent Python function, you can make it execute eagerly \n",
    "    with tf.config.run_functions_eagerly(True). This is a switch that \n",
    "    turns off Function's ability to create and run graphs, instead executing \n",
    "    the code normally.\n",
    "\"\"\"\n",
    "\n",
    "# Switching to eager mode\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "print(MSE_fn(t1, t2).numpy())\n",
    "\n",
    "# Returning back to graph execution\n",
    "tf.config.run_functions_eagerly(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tracing captures the TensorFlow operations into a graph, while python code is not captured in the graph. That graph is then executed without ever running the Python code again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.8282628>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = MSE_fn(t1, t1 * 1.25)\n",
    "y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Non-strict Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: indices[0] = 1 is not in [0, 1) [Op:GatherV2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.3], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unused_eager(xten):\n",
    "    tf.gather(xten, [1])\n",
    "    return xten\n",
    "\n",
    "t1 = tf.constant([2.3])\n",
    "\n",
    "try:\n",
    "    unused_eager(t1)\n",
    "\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(f'Error: {e}')\n",
    "    \n",
    "non_strict_func = tf.function(unused_eager)\n",
    "non_strict_func(t1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Best practices** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optimization benchmarks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### **Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4921d659dc345d00c547c20e6555ee899053119512e0511319e19b47447e7ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
